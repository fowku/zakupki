{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup, element\n",
    "import requests\n",
    "import datetime\n",
    "import time\n",
    "import csv\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GosParser:\n",
    "    def __init__(self, period_from, period_to, page=1, money_period=0, logging=True, interval=1, output='cards'):\n",
    "        self.base_url_start = 'https://zakupki.gov.ru/epz/order/extendedsearch/results.html?morphology=on&search-filter=Дате+размещения&pageNumber='\n",
    "        self.base_url_end = '&sortDirection=false&recordsPerPage=_50&showLotsInfoHidden=false&sortBy=UPDATE_DATE&fz44=on&fz223=on&pc=on'\n",
    "    \n",
    "        # logging flag\n",
    "        self.logging = logging\n",
    "\n",
    "        # output filename\n",
    "        self.output = output\n",
    "        \n",
    "        # date interval\n",
    "        self.interval = interval\n",
    "\n",
    "        # request headers\n",
    "        self.headers = {\n",
    "            'Accept-Encoding': 'gzip, deflate, br', \n",
    "            'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_4) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/83.0.4103.61 Safari/537.36',\n",
    "            'Connection': 'keep-alive', \n",
    "            'Accept-Language': 'ru-RU,ru;q=0.9,en-US;q=0.8,en;q=0.7',\n",
    "            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9',\n",
    "            'Upgrade-Insecure-Requests': '1',\n",
    "            'Host': 'zakupki.gov.ru',\n",
    "            'Sec-Fetch-Dest': 'document',\n",
    "            'Sec-Fetch-Mode': 'navigate',\n",
    "            'Sec-Fetch-Site': 'none',\n",
    "            'Sec-Fetch-User': '?1',\n",
    "            'Cache-Control': 'max-age=0',\n",
    "            'Cookie': '_ym_uid=1590413769299894330; _ym_d=1590413769; _ym_isad=2; _ym_visorc_36706425=b'\n",
    "        }\n",
    "        \n",
    "        # dates\n",
    "        self.start_period = datetime.date.fromisoformat(period_from)\n",
    "        self.end_period = datetime.date.fromisoformat(period_to)\n",
    "        self.current_period = datetime.date.fromisoformat(period_from)\n",
    "\n",
    "        # money periods\n",
    "        self.money = [[0, 400000], [400000, 1000000], [1000000, 5000000], [\n",
    "            5000000, 20000000], [20000000, 100000000], [100000000, 1000000000], [1000000000]]\n",
    "        self.current_money = money_period\n",
    "\n",
    "        # currencies\n",
    "        self.currency = {\n",
    "            '$': 'usd',\n",
    "            '€': 'eur',\n",
    "            '₽': 'rub' \n",
    "        }\n",
    "\n",
    "        self.current_page = page\n",
    "\n",
    "        # current link to parse\n",
    "        self.current_url = self.construct_url()\n",
    "\n",
    "    def construct_url(self):\n",
    "        url_page = self._add_page()\n",
    "        url_page_day = self._add_day(url_page)\n",
    "        url_page_day_money = self._add_money(url_page_day)\n",
    "\n",
    "        return url_page_day_money + '&currencyIdGeneral=-1'\n",
    "\n",
    "    def parse_cards(self):\n",
    "        # collect blocks\n",
    "        while self.current_period <= self.end_period:\n",
    "            while self.current_money != len(self.money) - 1:\n",
    "                # make very first iteration\n",
    "                page_blocks = self._collect_blocks()\n",
    "                # self.blocks.extend(page_blocks['data'])\n",
    "                self.current_page += 1\n",
    "                self.current_url = self.construct_url()\n",
    "\n",
    "                # read data from blocks while page has blocks\n",
    "                while ((page_blocks['status'] == 'timeout') or (page_blocks['status'] == 'ok' and len(page_blocks['data']) > 0)) and self.current_page < 20:\n",
    "                    page_blocks = self._collect_blocks()\n",
    "                    # self.blocks.extend(page_blocks['data'])\n",
    "                    self.current_page += 1\n",
    "                    self.current_url = self.construct_url()\n",
    "\n",
    "                # go to next money period\n",
    "                self.current_money += 1\n",
    "\n",
    "                # reset current page\n",
    "                self.current_page = 1\n",
    "\n",
    "                # reconstruct url using new data\n",
    "                self.current_url = self.construct_url()\n",
    "\n",
    "            # increment interval days\n",
    "            self.current_period += datetime.timedelta(days=self.interval)\n",
    "\n",
    "            # reset current money\n",
    "            self.current_money = 0\n",
    "\n",
    "            # reconstruct url using new data\n",
    "            self.current_url = self.construct_url()\n",
    "\n",
    "        # read blocks (cards)\n",
    "        self.blocks = pd.read_csv('cards.csv', parse_dates=True)\n",
    "\n",
    "    def _collect_blocks(self):        \n",
    "        try:\n",
    "            if self.logging:\n",
    "                print('page:', self.current_page, '| money:', self.money[self.current_money], '| date:', self.current_period)\n",
    "                \n",
    "            response = requests.get(self.current_url, headers=self.headers, verify=True, timeout=2)\n",
    "        except:\n",
    "            if self.logging:\n",
    "                print('timeout')\n",
    "            \n",
    "            self.write_to_csv([{\n",
    "                'date': self._create_iso_date_str(self.current_period.day, self.current_period.month, self.current_period.year),\n",
    "                'page': self.current_page,\n",
    "                'money': self.current_money\n",
    "            }], 'gaps.csv')\n",
    "            \n",
    "            return {\n",
    "                'data': [],\n",
    "                'status': 'timeout'\n",
    "            }\n",
    "\n",
    "        response.encoding = 'utf-8'\n",
    "        page = response.text\n",
    "        soup = BeautifulSoup(page, 'html.parser')\n",
    "\n",
    "        cards = soup.find_all(\n",
    "            'div', {'class': 'registry-entry__form'})\n",
    "\n",
    "        cards_data = []\n",
    "\n",
    "        for card in cards:\n",
    "            card_data = {}\n",
    "            price = card.find_all('div', {'class': 'price-block__value'})\n",
    "            link = card.find_all('div', {'class': 'registry-entry__header-mid__number'})\n",
    "                \n",
    "            # collect link, id and price, also add date, page and money period\n",
    "            if link and link[0] and price and price[0]:\n",
    "                a = link[0].find_all('a')\n",
    "                if a and a[0]:\n",
    "                    card_data['id'] = a[0].contents[0].strip()[2:]\n",
    "                    card_data['link'] = a[0]['href']\n",
    "                    \n",
    "                price = price[0].contents[0].strip()\n",
    "                card_data['price'] = float(price[:-2].replace(u'\\xa0', '').replace(' ', '').replace(',', '.'))\n",
    "\n",
    "                if price[-1] in self.currency:\n",
    "                    card_data['currency'] = self.currency[price[-1]]\n",
    "                else:\n",
    "                    card_data['currency'] = price[-1]\n",
    "                \n",
    "                # add current date\n",
    "                card_data['date'] = self._create_iso_date_str(self.current_period.day, self.current_period.month, self.current_period.year)\n",
    "\n",
    "                # add technical data (page and money period)\n",
    "                card_data['money'] = self.current_money\n",
    "                card_data['page'] = self.current_page\n",
    "\n",
    "                cards_data.append(card_data)\n",
    "\n",
    "        if len(cards_data) > 0:\n",
    "            self.write_to_csv(cards_data, 'cards.csv')\n",
    "        \n",
    "        return {\n",
    "            'data': cards_data,\n",
    "            'status': 'ok'\n",
    "        }\n",
    "    \n",
    "    def write_to_csv(self, data, file_name):\n",
    "        keys = data[0].keys()\n",
    "\n",
    "        with open(file_name, 'a+') as output_file:\n",
    "            dw = csv.DictWriter(output_file, keys)\n",
    "            dw.writerows(data)\n",
    "\n",
    "    def parse223(self, link):\n",
    "        headers = {\n",
    "            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9',\n",
    "            'Accept-Encoding': 'gzip, deflate, br',\n",
    "            'Accept-Language': 'ru-RU,ru;q=0.9,en-US;q=0.8,en;q=0.7',\n",
    "            'Cache-Control': 'max-age=0',\n",
    "            'Connection': 'keep-alive',\n",
    "            'Cookie': '_ym_uid=1590413769299894330; _ym_d=1590413769; _ym_isad=2; _ym_visorc_36706425=b',\n",
    "            'Host': 'zakupki.gov.ru',\n",
    "            'Sec-Fetch-Dest': 'document',\n",
    "            'Sec-Fetch-Mode': 'navigate',\n",
    "            'Sec-Fetch-Site': 'none',\n",
    "            'Sec-Fetch-User': '?1',\n",
    "            'Upgrade-Insecure-Requests': '1',\n",
    "            'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_4) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/83.0.4103.97 Safari/537.36'\n",
    "        }\n",
    "\n",
    "        lots_link = link.replace('common-info', 'lot-list')\n",
    "\n",
    "        try:    \n",
    "            main = requests.get(link, headers=headers, verify=True, timeout=2)\n",
    "            lots = requests.get(lots_link, headers=headers, verify=True, timeout=2)\n",
    "        except:\n",
    "            if self.logging:\n",
    "                print('timeout')\n",
    "\n",
    "            return None\n",
    "\n",
    "        purchase = {}\n",
    "        \n",
    "        # main page\n",
    "        main.encoding = 'utf-8'\n",
    "        soup_main = BeautifulSoup(main.text, 'html.parser')\n",
    "        table_main = soup_main.find_all('table')\n",
    "        table_customer = table_main[3]\n",
    "        rows = table_customer.find_all('tr')\n",
    "\n",
    "        for row in rows:\n",
    "            name = row.find_all('td')[0].contents[0]\n",
    "\n",
    "            if type(name) == element.Tag:\n",
    "                name = name.contents[0]\n",
    "            \n",
    "            if name == 'Наименование организации':\n",
    "                purchase['customer'] = row.find_all('td')[1].find('a').contents[0]\n",
    "\n",
    "            if name == 'Место нахождения' or name == 'Адрес места нахождения':\n",
    "                purchase['zipcode'] = row.find_all('td')[1].contents[0].split(',')[0].strip()\n",
    "                purchase['location'] = row.find_all('td')[1].contents[0].split(',')[1].strip()\n",
    "\n",
    "        # lots page\n",
    "        lots.encoding = 'utf-8'\n",
    "        soup_lots = BeautifulSoup(lots.text, 'html.parser')\n",
    "        table_lots = soup_lots.find(\n",
    "            'table', {'id': 'lot'})\n",
    "        headers = table_lots.find_all('th')\n",
    "        cells = table_lots.find_all('td')\n",
    "\n",
    "        for i in range(len(headers)):\n",
    "            if headers[i].contents[0].strip() == 'Классификация по ОКПД2':\n",
    "                purchase['lots'] = cells[i].contents[0].strip().replace(u'\\xa0', ' ').split(' ')[0]\n",
    "                purchase['num_of_lots'] = 1\n",
    "\n",
    "        return purchase\n",
    "\n",
    "    def parse_links(self):\n",
    "        for i in range(len(self.blocks)):\n",
    "            row = self.blocks.iloc[i]\n",
    "            root = 'https://zakupki.gov.ru'\n",
    "\n",
    "            if self.logging:\n",
    "                print(row.id)\n",
    "\n",
    "            # 223-ФЗ\n",
    "            if row.link.find('https') == 0:\n",
    "                link = row.link\n",
    "                parsed = self.parse223(link)\n",
    "\n",
    "                row_dict = row.to_dict()\n",
    "                del row_dict['money']\n",
    "                del row_dict['page']\n",
    "                \n",
    "                if parsed:\n",
    "                    res = dict(row_dict, **parsed);\n",
    "                    self.write_to_csv([res], self.output + '.csv')\n",
    "\n",
    "            # 44-ФЗ / zk504\n",
    "            else:\n",
    "                link = root + row.link\n",
    "                parsed = self.parse44(link)\n",
    "\n",
    "                row_dict = row.to_dict()\n",
    "                del row_dict['money']\n",
    "                del row_dict['page']\n",
    "                row_dict['link'] = link\n",
    "                \n",
    "                if parsed:\n",
    "                    res = dict(row_dict, **parsed);\n",
    "                    self.write_to_csv([res], self.output + '.csv')\n",
    "\n",
    "    def parse44(self, link):\n",
    "        try:    \n",
    "            main = requests.get(link, headers=self.headers, verify=True, timeout=2)\n",
    "        except:\n",
    "            print('timeout')\n",
    "            return None\n",
    "\n",
    "        purchase = {}\n",
    "        \n",
    "        # page\n",
    "        main.encoding = 'utf-8'\n",
    "        soup = BeautifulSoup(main.text, 'html.parser')\n",
    "        h2s = soup.find_all('h2')\n",
    "        row_blockInfos = soup.find_all('div', {'class': 'row blockInfo'})\n",
    "\n",
    "        contact_i = -1\n",
    "        table_i = -1\n",
    "        for i in range(len(h2s)):\n",
    "            if h2s[i].contents[0] == 'Контактная информация':\n",
    "                contact_i = i\n",
    "\n",
    "            if h2s[i].contents[0] == 'Информация об объекте закупки':\n",
    "                table_i = i\n",
    "\n",
    "        if contact_i > -1:\n",
    "            titles = row_blockInfos[contact_i].find_all('span', {'class': 'section__title'})\n",
    "            infos = row_blockInfos[contact_i].find_all('span', {'class': 'section__info'})\n",
    "\n",
    "        for i in range(len(titles)):\n",
    "            if titles[i].contents[0].strip() == 'Место нахождения':\n",
    "                try:\n",
    "                    zipcode = int(infos[i].contents[0].strip().split(',')[1].strip())\n",
    "                except:\n",
    "                    return None\n",
    "\n",
    "                purchase['zipcode'] = zipcode\n",
    "                purchase['location'] = infos[i].contents[0].strip().split(',')[2].strip()\n",
    "\n",
    "            if titles[i].contents[0].strip() == 'Организация, осуществляющая размещение' or titles[i].contents[0].strip() == 'Наименование организации':\n",
    "                purchase['customer'] = infos[i].contents[0].strip()\n",
    "\n",
    "        if table_i > -1:\n",
    "            table = row_blockInfos[table_i].find('table')\n",
    "\n",
    "            headers = table.find_all('th')\n",
    "            cells = table.find('tbody').find_all('td')\n",
    "\n",
    "            column = -1\n",
    "            for i in range(len(headers)):\n",
    "                if headers[i].contents[0].strip() == 'Код позиции':\n",
    "                    column = i + 1\n",
    "                    break\n",
    "\n",
    "            rows = table.find('tbody').find_all('tr', {'class': 'tableBlock__row'}, recursive=False)\n",
    "            \n",
    "            lots = []\n",
    "            for row in rows:\n",
    "                cells = row.find_all('td')\n",
    "\n",
    "                if len(cells) > 0 and column > -1:\n",
    "                    lot = cells[column]\n",
    "\n",
    "                    if lot.find('a'):\n",
    "                        lot = lot.find('a').contents[0]\n",
    "                    else:\n",
    "                        lot = lot.contents[0]\n",
    "\n",
    "                    lots.append(lot.strip().split('-')[0])\n",
    "\n",
    "            purchase['lots'] = ', '.join(lots)\n",
    "            purchase['num_of_lots'] = len(lots)\n",
    "\n",
    "        if purchase['num_of_lots'] == 0:\n",
    "            return None\n",
    "            \n",
    "        return purchase\n",
    "\n",
    "    def _create_date_str(self, day, month, year):\n",
    "        return str(day).zfill(2) + '.' + str(month).zfill(2) + '.' + str(year)\n",
    "    \n",
    "    def _create_iso_date_str(self, day, month, year):\n",
    "        return str(year) + '-' + str(month).zfill(2) + '-' + str(day).zfill(2)\n",
    "\n",
    "    def _add_day(self, url):\n",
    "        date = self._create_date_str(self.current_period.day, self.current_period.month, self.current_period.year)\n",
    "        return url + '&publishDateFrom=' + date + '&publishDateTo=' + date\n",
    "\n",
    "    def _add_money(self, url):\n",
    "        money_period = self.money[self.current_money]\n",
    "\n",
    "        if (len(money_period) == 2):\n",
    "            return url + '&priceFromGeneral=' + str(money_period[0]) + '&priceToGeneral=' + str(money_period[1])\n",
    "        else:\n",
    "            return url + '&priceFromGeneral=' + str(money_period[0])\n",
    "\n",
    "    def _add_page(self):\n",
    "        return self.base_url_start + str(self.current_page) + self.base_url_end\n",
    "\n",
    "    def _next_page(self):\n",
    "        self.current_page += 1\n",
    "        self.current_url = self.construct_url()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true,
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "parser = GosParser(period_from='2019-06-01', period_to='2019-06-01', output='data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "page: 1 | money: [0, 400000] | date: 2019-06-01\npage: 2 | money: [0, 400000] | date: 2019-06-01\npage: 3 | money: [0, 400000] | date: 2019-06-01\npage: 4 | money: [0, 400000] | date: 2019-06-01\npage: 1 | money: [400000, 1000000] | date: 2019-06-01\npage: 2 | money: [400000, 1000000] | date: 2019-06-01\npage: 1 | money: [1000000, 5000000] | date: 2019-06-01\npage: 2 | money: [1000000, 5000000] | date: 2019-06-01\npage: 1 | money: [5000000, 20000000] | date: 2019-06-01\npage: 2 | money: [5000000, 20000000] | date: 2019-06-01\npage: 1 | money: [20000000, 100000000] | date: 2019-06-01\npage: 2 | money: [20000000, 100000000] | date: 2019-06-01\npage: 1 | money: [100000000, 1000000000] | date: 2019-06-01\npage: 2 | money: [100000000, 1000000000] | date: 2019-06-01\n"
    }
   ],
   "source": [
    "parser.parse_cards()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "103200008419004518\n31907944880\n31907944871\n31907944883\n31907944859\n860200000819006211\n31907944977\n31907944869\n31907944868\n31907944981\n31907944964\n31907944975\n31907944962\n31907944983\n31907944986\n860200000819006210\n860200000819006190\n860200000819006188\n360200051219000021\n860200000819006194\n860200000819006189\n860200000819005981\n31907944968\n330200000419000118\n360200017919000190\n860200000819006212\n860200000819006197\n860200000819006200\n860200000819006198\n130200002419001884\n130200002419001883\n813500000119005375\n813500000119005406\n860200000819006195\n860200000819006216\n860200000819006193\n31907944970\n860200000819006217\n860200000819006203\n860200000819006204\n860200000819006209\n860200000819006206\n860200000819006201\n860200000819006215\n372200156719000013\n31907944992\n31907944991\n31907944987\n31907944984\n31907944980\n31907944979\n31907944978\n31907944976\n31907944974\n31907944963\n31907944884\n31907944900\n31907944914\n860200000819006207\n860200000819006192\n860200000819006191\n360200018519000026\n345200005319000161\n31907944955\n31907944957\n31907944956\n31907944954\n31907944949\n360200051219000020\n860200000819005975\n130200002419001885\n156300000419000077\n573200004119000002\n813500000119005386\n31907944952\n31907944938\n31907944874\n360300020219000014\n373200041519000867\n31907944942\n31907944944\n31907944945\n31907944946\n31907944972\n31907944866\n31907944867\n551300014619000003\n31907944904\n31907944902\n31907944858\n31907944931\n31907944936\n31907944967\n31907944971\n151300013919000010\n151300013919000009\n31907944965\n351300018319000008\n31907944933\n31907944894\n31907944947\n31907944873\n151300029019000006\n31907944937\n31907944930\n31907944929\n31907944928\n31907944927\n31907944926\n31907944925\n31907944924\n31907944923\n31907944922\n31907944921\n31907944919\n330500000719000093\n31907944918\n31907944917\n31907944915\n31907944913\n31907944912\n31907944910\n31907944909\n31907944907\n31907944906\n31907944905\n31907944903\n31907944916\n31907944911\n31907944898\n31907944893\n31907944892\n373200633019000002\n31907944875\n373200138919000002\n31907944855\n31907944853\n31907944847\n31907944870\n31907944885\n31907944883\n31907944865\n31907944982\n31907944849\n31907944899\n860200000819006199\n135200000519002224\n358300100919000069\n172300009719000027\n813500000119005396\n813500000119005391\n813500000119005399\n101300074119000001\n172300009119000014\n31907944940\n31907944943\n31907944862\n31907944897\n31907944994\n31907944958\n31907944990\n31907944961\n31907944882\n31907944881\n31907944879\n31907944877\n31907944939\n31907944896\n373200138919000001\n31907944953\n31907944901\n173200000319000014\n163300024719000038\n848300046019000319\n31907944951\n355300069419000003\n31907944861\n31907944973\n135200000519002227\n31907944908\n806500000219000414\n31907944935\n191300046519000003\n358300100919000070\n31907944959\n162300003619000095\n31907944854\n31907944941\n169200002119000018\n312300015219000002\n31907944966\n31907944872\n31907944948\n31907944863\n31907944851\n31907944850\n31907944950\n31907944864\n31907944876\n31907944887\n31907944886\n31907944969\n848300046019000320\n31907944920\n158300024019000001\n373200078019000001\n31907944852\n350300030419000075\n330300051919000060\n136300050519000061\n31907944960\n103300019719000013\n103300019719000011\n187300010319000585\n31907944856\n31907944891\n31907944890\n31907944889\n31907944888\n132300008019000069\n103300019719000012\n103300019719000010\n314300002419000017\n31907944860\n31907944934\n31907944857\n158300015519000013\n"
    }
   ],
   "source": [
    "parser.parse_links()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.3 64-bit",
   "language": "python",
   "name": "python37364bitd47521be79024829aec57eaa9e737e57"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}